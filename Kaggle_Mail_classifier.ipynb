{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    date               org            tld  \\\n",
       "0  Mon, 15 Oct 2018 08:03:09 +0000 (UTC)  researchgatemail            net   \n",
       "1  Thu, 17 Apr 2014 09:12:33 -0700 (PDT)             no-ip            com   \n",
       "2        Thu, 27 Oct 2016 01:36:28 +0000              mail  goodreads.com   \n",
       "3  Fri, 16 Oct 2020 08:06:31 +0000 (GMT)       insideapple      apple.com   \n",
       "4        Thu, 02 Jul 2015 10:16:46 +0000           twitter            com   \n",
       "\n",
       "   ccs  bcced              mail_type  images  urls  salutations  designation  \\\n",
       "0    0      0  multipart/alternative       4    28            0            1   \n",
       "1    0      0  multipart/alternative       6    32            0            0   \n",
       "2    0      0        multipart/mixed       0     0            0            0   \n",
       "3    0      0  multipart/alternative     108   171            0            0   \n",
       "4    0      0  multipart/alternative      20   166            0            0   \n",
       "\n",
       "   chars_in_subject  chars_in_body  updates  personal  promotions  forums  \\\n",
       "0              47.0          25556        0         1           0       0   \n",
       "1              46.0          19930        1         1           0       0   \n",
       "2              21.0              4        0         1           0       0   \n",
       "3              52.0          96568        0         0           1       0   \n",
       "4              81.0          95131        0         1           0       0   \n",
       "\n",
       "   purchases  travel  spam  social  \n",
       "0          0       0     0       1  \n",
       "1          0       0     0       0  \n",
       "2          0       0     0       1  \n",
       "3          0       0     0       0  \n",
       "4          0       0     0       1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>org</th>\n      <th>tld</th>\n      <th>ccs</th>\n      <th>bcced</th>\n      <th>mail_type</th>\n      <th>images</th>\n      <th>urls</th>\n      <th>salutations</th>\n      <th>designation</th>\n      <th>chars_in_subject</th>\n      <th>chars_in_body</th>\n      <th>updates</th>\n      <th>personal</th>\n      <th>promotions</th>\n      <th>forums</th>\n      <th>purchases</th>\n      <th>travel</th>\n      <th>spam</th>\n      <th>social</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mon, 15 Oct 2018 08:03:09 +0000 (UTC)</td>\n      <td>researchgatemail</td>\n      <td>net</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>4</td>\n      <td>28</td>\n      <td>0</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>25556</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Thu, 17 Apr 2014 09:12:33 -0700 (PDT)</td>\n      <td>no-ip</td>\n      <td>com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>6</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46.0</td>\n      <td>19930</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thu, 27 Oct 2016 01:36:28 +0000</td>\n      <td>mail</td>\n      <td>goodreads.com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/mixed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fri, 16 Oct 2020 08:06:31 +0000 (GMT)</td>\n      <td>insideapple</td>\n      <td>apple.com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>108</td>\n      <td>171</td>\n      <td>0</td>\n      <td>0</td>\n      <td>52.0</td>\n      <td>96568</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Thu, 02 Jul 2015 10:16:46 +0000</td>\n      <td>twitter</td>\n      <td>com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>20</td>\n      <td>166</td>\n      <td>0</td>\n      <td>0</td>\n      <td>81.0</td>\n      <td>95131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "\n",
    "#################### imports ####################\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#################### Read csvs ####################\n",
    "train_data = pd.read_csv('train_ml.csv', index_col=0)\n",
    "test_data = pd.read_csv('test_ml.csv', index_col=0)\n",
    "\n",
    "### preview ###\n",
    "train_data.head()\n",
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding mailtype\n",
    "mt1,mt2=[],[]\n",
    "for mt in train_data['mail_type']:\n",
    "    if isinstance(mt,str):\n",
    "        mt1.append(mt.split('/')[0])\n",
    "        if len(mt.split('/'))>1:\n",
    "            mt2.append(mt.split('/')[1])\n",
    "        else:\n",
    "            mt2.append('None')\n",
    "    else:\n",
    "        mt1.append('None')\n",
    "        mt2.append('None')\n",
    "\n",
    "train_data['mt1']=mt1\n",
    "train_data['mt2']=mt2\n",
    "\n",
    "mt1,mt2=[],[]\n",
    "for mt in test_data['mail_type']:\n",
    "    if isinstance(mt,str):\n",
    "        mt1.append(mt.split('/')[0])\n",
    "        if len(mt.split('/'))>1:\n",
    "            mt2.append(mt.split('/')[1])\n",
    "        else:\n",
    "            mt2.append('None')\n",
    "    else:\n",
    "        mt1.append('None')\n",
    "        mt2.append('None')\n",
    "\n",
    "test_data['mt1']=mt1\n",
    "test_data['mt2']=mt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              date      org          tld  ccs  bcced  \\\n",
       "0  Thu, 13 Jul 2017 08:55:57 +0000  twitter          com    0      0   \n",
       "1  Sun, 30 Sep 2018 14:42:12 +0000   mailer  netflix.com    0      0   \n",
       "2  Mon, 13 Feb 2017 10:47:00 +0530    iiitd        ac.in    0      0   \n",
       "3  Thu, 16 Jun 2016 09:56:23 +0000  twitter          com    0      0   \n",
       "4  Mon, 18 Apr 2016 01:51:59 +0530    iiitd        ac.in    0      0   \n",
       "\n",
       "               mail_type  images  urls  salutations  designation  ...  mm  ss  \\\n",
       "0  multipart/alternative       7    56            0            0  ...  55  57   \n",
       "1  multipart/alternative       5    33            0            0  ...  42  12   \n",
       "2             text/plain       0     2            1            0  ...  47   0   \n",
       "3  multipart/alternative       8    53            0            0  ...  56  23   \n",
       "4        multipart/mixed       0     0            0            0  ...  51  59   \n",
       "\n",
       "     d    m     y    fus  fus2         hm s0  w  \n",
       "0  Thu  Jul  2017  +0000  None   8.916667  0  1  \n",
       "1  Sun  Sep  2018  +0000  None  14.700000  0  0  \n",
       "2  Mon  Feb  2017  +0530  None  10.783333  0  1  \n",
       "3  Thu  Jun  2016  +0000  None   9.933333  0  1  \n",
       "4  Mon  Apr  2016  +0530  None   1.850000  0  1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>org</th>\n      <th>tld</th>\n      <th>ccs</th>\n      <th>bcced</th>\n      <th>mail_type</th>\n      <th>images</th>\n      <th>urls</th>\n      <th>salutations</th>\n      <th>designation</th>\n      <th>...</th>\n      <th>mm</th>\n      <th>ss</th>\n      <th>d</th>\n      <th>m</th>\n      <th>y</th>\n      <th>fus</th>\n      <th>fus2</th>\n      <th>hm</th>\n      <th>s0</th>\n      <th>w</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thu, 13 Jul 2017 08:55:57 +0000</td>\n      <td>twitter</td>\n      <td>com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>7</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>55</td>\n      <td>57</td>\n      <td>Thu</td>\n      <td>Jul</td>\n      <td>2017</td>\n      <td>+0000</td>\n      <td>None</td>\n      <td>8.916667</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sun, 30 Sep 2018 14:42:12 +0000</td>\n      <td>mailer</td>\n      <td>netflix.com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>5</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>42</td>\n      <td>12</td>\n      <td>Sun</td>\n      <td>Sep</td>\n      <td>2018</td>\n      <td>+0000</td>\n      <td>None</td>\n      <td>14.700000</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mon, 13 Feb 2017 10:47:00 +0530</td>\n      <td>iiitd</td>\n      <td>ac.in</td>\n      <td>0</td>\n      <td>0</td>\n      <td>text/plain</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>47</td>\n      <td>0</td>\n      <td>Mon</td>\n      <td>Feb</td>\n      <td>2017</td>\n      <td>+0530</td>\n      <td>None</td>\n      <td>10.783333</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Thu, 16 Jun 2016 09:56:23 +0000</td>\n      <td>twitter</td>\n      <td>com</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/alternative</td>\n      <td>8</td>\n      <td>53</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>56</td>\n      <td>23</td>\n      <td>Thu</td>\n      <td>Jun</td>\n      <td>2016</td>\n      <td>+0000</td>\n      <td>None</td>\n      <td>9.933333</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mon, 18 Apr 2016 01:51:59 +0530</td>\n      <td>iiitd</td>\n      <td>ac.in</td>\n      <td>0</td>\n      <td>0</td>\n      <td>multipart/mixed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>51</td>\n      <td>59</td>\n      <td>Mon</td>\n      <td>Apr</td>\n      <td>2016</td>\n      <td>+0530</td>\n      <td>None</td>\n      <td>1.850000</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### adding hour and date\n",
    "hh,mm,ss,d,m,y,fus,fus2=[],[],[],[],[],[],[],[]\n",
    "for date in train_data['date']:\n",
    "    hh.append(int(date.split(':')[0].split(' ')[-1]))\n",
    "    \n",
    "    mm.append(int(date.split(':')[1]))\n",
    "    \n",
    "    ss.append(int(date.split(':')[2].split(' ')[0]))\n",
    "    \n",
    "    if len(date.split(':')[0].split(',')[0])==3:\n",
    "        d.append(str(date.split(':')[0].split(',')[0]))\n",
    "    else:\n",
    "        d.append('None')\n",
    "    \n",
    "    if len(date.split(':')[0].split(' '))==5:\n",
    "        if len(date.split(':')[0].split(' ')[2])==3:\n",
    "            m.append(str(date.split(':')[0].split(' ')[2]))\n",
    "        else:\n",
    "            m.append('None')\n",
    "    else:\n",
    "        m.append(0)\n",
    "    \n",
    "    if len(date.split(':')[0].split(' '))==5:\n",
    "        if len(date.split(':')[0].split(' ')[3])==4:\n",
    "            y.append(str(date.split(':')[0].split(' ')[3]))\n",
    "        else:\n",
    "            y.append('None')\n",
    "    else:\n",
    "        y.append('None')\n",
    "    \n",
    "    if len(date.split())>=6:\n",
    "        fus.append(date.split()[5])\n",
    "        if len(date.split())>=7:\n",
    "            fus2.append(date.split()[6])\n",
    "        else:\n",
    "            fus2.append('None')\n",
    "    else:\n",
    "        fus.append('None')\n",
    "        fus2.append('None')\n",
    "\n",
    "train_data['hh']=hh\n",
    "train_data['mm']=mm\n",
    "train_data['ss']=ss\n",
    "train_data['d']=d\n",
    "train_data['m']=m\n",
    "train_data['y']=y\n",
    "train_data['fus']=fus\n",
    "train_data['fus2']=fus2\n",
    "\n",
    "hm=[]\n",
    "for i in range(len(hh)):\n",
    "    hm.append(float(hh[i])+float(mm[i])/60)\n",
    "train_data['hm']=hm\n",
    "\n",
    "s0=[]\n",
    "for s in ss:\n",
    "    if ss=='00':\n",
    "        s0.append(1)\n",
    "    else:\n",
    "        s0.append(0)\n",
    "train_data['s0']=s0\n",
    "\n",
    "weekend=['Sat','Sun']\n",
    "\n",
    "w=[]\n",
    "for day in d:\n",
    "    if day in weekend:\n",
    "        w.append(0)\n",
    "    else:\n",
    "        w.append(1)\n",
    "\n",
    "train_data['w']=w\n",
    "\n",
    "hh,mm,ss,d,m,y,fus,fus2=[],[],[],[],[],[],[],[]\n",
    "for date in test_data['date']:\n",
    "    hh.append(int(date.split(':')[0].split(' ')[-1]))\n",
    "    \n",
    "    mm.append(int(date.split(':')[1]))\n",
    "    \n",
    "    ss.append(int(date.split(':')[2].split(' ')[0]))\n",
    "    \n",
    "    if len(date.split(':')[0].split(',')[0])==3:\n",
    "        d.append(str(date.split(':')[0].split(',')[0]))\n",
    "    else:\n",
    "        d.append('None')\n",
    "    \n",
    "    if len(date.split(':')[0].split(' '))==5:\n",
    "        if len(date.split(':')[0].split(' ')[2])==3:\n",
    "            m.append(str(date.split(':')[0].split(' ')[2]))\n",
    "        else:\n",
    "            m.append('None')\n",
    "    else:\n",
    "        m.append(0)\n",
    "    \n",
    "    if len(date.split(':')[0].split(' '))==5:\n",
    "        if len(date.split(':')[0].split(' ')[3])==4:\n",
    "            y.append(str(date.split(':')[0].split(' ')[3]))\n",
    "        else:\n",
    "            y.append('None')\n",
    "    else:\n",
    "        y.append('None')\n",
    "    \n",
    "    if len(date.split())>=6:\n",
    "        fus.append(date.split()[5])\n",
    "        if len(date.split())>=7:\n",
    "            fus2.append(date.split()[6])\n",
    "        else:\n",
    "            fus2.append('None')\n",
    "    else:\n",
    "        fus.append('None')\n",
    "        fus2.append('None')\n",
    "\n",
    "test_data['hh']=hh\n",
    "test_data['mm']=mm\n",
    "test_data['ss']=ss\n",
    "test_data['d']=d\n",
    "test_data['m']=m\n",
    "test_data['y']=y\n",
    "test_data['fus']=fus\n",
    "test_data['fus2']=fus2\n",
    "\n",
    "hm=[]\n",
    "for i in range(len(hh)):\n",
    "    hm.append(float(hh[i])+float(mm[i])/60)\n",
    "test_data['hm']=hm\n",
    "\n",
    "s0=[]\n",
    "for s in ss:\n",
    "    if ss=='00':\n",
    "        s0.append(1)\n",
    "    else:\n",
    "        s0.append(0)\n",
    "test_data['s0']=s0\n",
    "\n",
    "weekend=['Sat','Sun']\n",
    "\n",
    "w=[]\n",
    "for day in d:\n",
    "    if day in weekend:\n",
    "        w.append(0)\n",
    "    else:\n",
    "        w.append(1)\n",
    "\n",
    "test_data['w']=w\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Filtering columns ####################\n",
    "### numeric features\n",
    "train_x_num = train_data.iloc[:,[3,4,6,7,8,9,10,11,-3,-2,-1]]\n",
    "train_x_num = train_x_num.fillna(value=0)\n",
    "\n",
    "train_y = train_data[['updates', 'personal', 'promotions',\n",
    "                        'forums', 'purchases', 'travel',\n",
    "                        'spam', 'social']]\n",
    "\n",
    "test_x_num = test_data.iloc[:,[3,4,6,7,8,9,10,11,-3,-2,-1]]\n",
    "test_x_num = test_x_num.fillna(value=0)\n",
    "\n",
    "### string features \n",
    "test_x_str = test_data.iloc[:,[1,2,-4,-5,5]]\n",
    "test_x_str = test_x_str.fillna(value='None')\n",
    "\n",
    "train_x_str = train_data.iloc[:,[1,2,-4,-5,5]]\n",
    "train_x_str = train_x_str.fillna(value='None')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Processing ####################\n",
    "feat_enc = OneHotEncoder()\n",
    "feat_enc.fit(np.vstack([train_x_str, test_x_str]))\n",
    "train_x_str_enc = feat_enc.transform(train_x_str).A\n",
    "test_x_str_enc = feat_enc.transform(test_x_str).A\n",
    "\n",
    "train_x_final=np.hstack((train_x_str_enc,train_x_num))\n",
    "test_x_final=np.hstack((test_x_str_enc,test_x_num))\n",
    "\n",
    "pca=PCA()\n",
    "#pca.fit_transform(train_x_final)\n",
    "#pca.fit_transform(test_x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... ... ... ... ... ... ... ... ... ... Training\n",
      "training time: 405.222 s\n",
      "... ... ... ... ... ... ... ... ... ... Predicting\n",
      "prediction time: 9.141 s\n",
      "prediction labels shape: (17002, 8)\n"
     ]
    }
   ],
   "source": [
    "#################### Training ####################\n",
    "\n",
    "classif = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "\n",
    "### Fit\n",
    "print('... ... ... ... ... ... ... ... ... ... Training')\n",
    "t0=time.time()\n",
    "classif.fit(train_x_final, train_y)\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")\n",
    "\n",
    "### Predict\n",
    "print('... ... ... ... ... ... ... ... ... ... Predicting')\n",
    "t1=time.time()\n",
    "pred_y = classif.predict_proba(test_x_final)\n",
    "print(\"prediction time:\", round(time.time()-t1, 3), \"s\")\n",
    "print('prediction labels shape:', pred_y.shape)\n",
    "\n",
    "### Saving the submission file\n",
    "pred_data = pd.DataFrame(pred_y, columns=['updates', 'personal', 'promotions','forums', 'purchases', 'travel','spam', 'social'])\n",
    "pred_data.to_csv(\"randomforest.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}